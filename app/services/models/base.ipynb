{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzKIl25w_Ad8"
      },
      "source": [
        "# \"Hype\" is all you need #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0zQVZQk_KWM"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S5_9281_7Ez"
      },
      "source": [
        "The motivation behind the project is to work as a team with the idea of joining everthing we've seen, in other words:\n",
        "\n",
        "Being able to design, research, develop and deploy a Data Science idea designing a Big Data Architecture from which to train a model with a conclusion in mind while being ethical and not breaking any EU laws"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USjXwBaT_wz7"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCJwQ-tM_62T"
      },
      "source": [
        "This is research into what defines the success of films, and whether success can be predicted (proportionally) based on the hype (expectation) generated around a film; to be able to be expandable with both series and anime, video games or any other type of multimedia content or not.\n",
        "\n",
        "It is intended, as possible definitions of the success of a film, to be able to predict:\n",
        "\n",
        "- The collection of a film based on its initial investment and how much good it will be received\n",
        "\n",
        "- The acceptance/acclamation of a film with respect to the initial \"hype\"\n",
        "\n",
        "- Predict the note on IMDB a week after release, and whoever says IMDB can say other platforms (Rotten Tomatoes, Metacritic)\n",
        "\n",
        "- Predict your success (previously defined) one week after your release\n",
        "\n",
        "\n",
        "For this, various data sources will be used, such as: Twitter, Reddit, YouTube, IMDB, and those that we can discover as the investigation progresses. One of the main and central components of the application is sentiment analysis, which would become the main focus of the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MyXGmCQ_yP8"
      },
      "source": [
        "### Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IqedD-8_6o1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iya--2fs_0Ba"
      },
      "source": [
        "### Product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EZ_OW0K_6bj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYu4Gi_V_2DM"
      },
      "source": [
        "### Assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y69aV9xFwMz"
      },
      "source": [
        "#### Chosen Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5pWXLJ8_6Oc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJy3RLmRF0oa"
      },
      "source": [
        "##### Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYppIwfPF06q"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dELGRxWbF3r1"
      },
      "source": [
        "##### How does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "968ai2J9F5kb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC_BdVCtF6OS"
      },
      "source": [
        "##### Why not...?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCeEbNcCF8fZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQAUx45K_MWE"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V1txFPVDZ_j"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ly2XM7ZYDdR0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVUE5DYuACJz"
      },
      "source": [
        "### Load ENV Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gMzIeEYuBGqC"
      },
      "outputs": [],
      "source": [
        "COLAB_MOUNT_PATH = \"/content/drive/\" #@param {type:\"string\"}\n",
        "\n",
        "COLAB_UNIT_NAME = \"MyDrive\" #@param {type:\"string\"}\n",
        "\n",
        "BASEPATH = \"Colab Notebooks\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KXjYpj6AE0D"
      },
      "source": [
        "### Load system elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvWsPjmsyfIK"
      },
      "source": [
        "The argument `-q` is used as to not overflow the notebook with the installation progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XsofrGH_Cyi7"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Ztkmat_udj"
      },
      "source": [
        "### Mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H7jHBrmAMv8",
        "outputId": "3d382469-f2b7-4301-e3ad-a4d2afc93b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount(COLAB_MOUNT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8royPCx5_85z"
      },
      "source": [
        "### Move to the path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6uAoz7YDgdj"
      },
      "source": [
        "Generate the directory's full path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E1X1bpoA90U",
        "outputId": "89fd9e6a-4cf9-42b6-9c4b-2380603e7acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The working directory has been detected as: /content/drive/MyDrive/Colab Notebooks/NLP\n"
          ]
        }
      ],
      "source": [
        "working_path = os.path.join( COLAB_MOUNT_PATH, COLAB_UNIT_NAME, BASEPATH )\n",
        "print(f'The working directory has been detected as:', working_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X8xb85jDjv7"
      },
      "source": [
        "Attempt to move to the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-89gwuBCDlYa",
        "outputId": "193936b5-6958-42a1-edc5-561bc8977008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moved successfully to the desired directory\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  os.chdir( working_path )\n",
        "  print('Moved successfully to the desired directory')\n",
        "except Exception:\n",
        "  print('Coudln\\'t move to the desired directory')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJC36d_xDsv7"
      },
      "source": [
        "Now the current directory is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ogr_ygUzDvBL",
        "outputId": "110cfecf-b512-4feb-9a8e-7b6ec3f3e5d2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/NLP'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izSzSLvc_Sl7"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRA7jaZUNozx"
      },
      "source": [
        "At this point we need to instantiate all the data related to our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e8rbnooDXUT"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qNFHYiApD_Y6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAyQnh5hDYeT"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXHzTOw_FAm1"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv('dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXLlf-UPLP9x"
      },
      "source": [
        "### Check that it's right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxbY-OqrLTWx"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qvBxmJpdqfm"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_I1__AtlLHU"
      },
      "source": [
        "This should not be touched lightly, these are values you can modify by giving a value, they only serve as the default, and may affect to many cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ADHdde3BdsER"
      },
      "outputs": [],
      "source": [
        "FIGURE_WIDTH = 30 #@param {type:\"number\"}\n",
        "FIGURE_HEIGHT = 10 #@param {type:\"number\"}\n",
        "\n",
        "WHITEGRID = 'whitegrid' #@param {type:\"string\"}\n",
        "WHITE = 'white' #@param {type:\"string\"}\n",
        "COLOR_MAP = 'BuGn' #@param {type:\"string\"}\n",
        "\n",
        "SUBPLOT_ADJUSTMENT = {\n",
        "  'left'  : 0.1,\n",
        "  'bottom': 0.1,\n",
        "  'right' : 0.9,\n",
        "  'top'   : 0.9,\n",
        "  'wspace': 0.4,\n",
        "  'hspace': 0.4,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Ju_VeQdPn1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hSZspC3dQo-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandas.api.types import is_numeric_dtype, is_string_dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-24PGyXvRP7"
      },
      "source": [
        "### Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o19frArtid5W"
      },
      "outputs": [],
      "source": [
        "def set_plotting_style(\n",
        "  style: str = WHITE,\n",
        "  fig_width: float = FIGURE_WIDTH,\n",
        "  fig_height: float = FIGURE_HEIGHT,\n",
        ") -> None:\n",
        "  \"\"\"Configures the plotting style\"\"\"\n",
        "  sns.set_theme(style=style)\n",
        "  plt.figure(figsize=(fig_width, fig_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqEy4hkivOxC"
      },
      "outputs": [],
      "source": [
        "def get_df_with_cols(\n",
        "  dataframe = pd.DataFrame,\n",
        "  cols: Tuple[str] = None,\n",
        "  only_numeric: bool = False,\n",
        "  only_strings: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "  \"\"\"Gets the dataframe with the given columns\"\"\"\n",
        "  # Backup the dataframe\n",
        "  df = dataframe.copy()\n",
        "\n",
        "  # If no columns are given, get every column\n",
        "  if not cols:\n",
        "    columns = tuple(df.columns)\n",
        "\n",
        "  def filter_by(col) -> bool:\n",
        "    \"\"\"Determines if a col should be stored\"\"\"\n",
        "    if only_numeric:\n",
        "      return is_numeric_dtype(col)\n",
        "    elif only_strings:\n",
        "      return is_string_dtype(col)\n",
        "\n",
        "    return True\n",
        "\n",
        "  columns = [ col for col in columns if filter_by(df[col]) ]\n",
        "  df = df[ columns ]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV1nPnO9LXpx"
      },
      "source": [
        "### Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnPa7GydxkED"
      },
      "source": [
        "It will return the percentage **per** columns, which will work wonders for an overall view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrccPyGwwXv7"
      },
      "outputs": [],
      "source": [
        "def get_na_percentage(\n",
        "  dataframe: pd.DataFrame,\n",
        ") -> pd.DataFrame:\n",
        "  \"\"\"Returns the percentage of missing values in a dataframe per column\"\"\"\n",
        "  return dataframe.isna().sum() * 100 / len(dataframe)\n",
        "\n",
        "get_na_percentage(dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9_U0NLTxq4p"
      },
      "source": [
        "While now we may want to retrieve the percentage on the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdg5WrePyIQi"
      },
      "outputs": [],
      "source": [
        "def get_total_na_percentage(\n",
        "  dataframe: pd.DataFrame,\n",
        ") -> float:\n",
        "  \"\"\"Returns the total percentage of missing values in a dataframe\"\"\"\n",
        "  return dataframe.isna().sum().sum() * 100 / (len(dataframe) * len(dataframe.columns))\n",
        "\n",
        "get_total_na_percentage(dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKPxfQ76LY0h"
      },
      "source": [
        "### Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IHNDAIpu2pD"
      },
      "source": [
        "The correlation helps us identify which values contribute and further explain the dependant variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qOYsF5-xQRa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfWmO1TNvdMT"
      },
      "outputs": [],
      "source": [
        "def get_correlation(\n",
        "  dataframe=pd.DataFrame,\n",
        ") -> pd.DataFrame:\n",
        "  \"\"\"Gets the DataFrame correlation\"\"\"\n",
        "  return get_df_with_cols(\n",
        "    dataframe=dataframe,\n",
        "    only_numeric=True\n",
        "  ).corr()\n",
        "\n",
        "correlation = get_correlation(dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yMBMCRUxLUM"
      },
      "source": [
        "To easily identify the correlation we create a method to plot it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fxf3PG0u2Hb"
      },
      "outputs": [],
      "source": [
        "def plot_correlation(\n",
        "  dataframe=pd.DataFrame,\n",
        "  cmap: str = COLOR_MAP,\n",
        ") -> None:\n",
        "  \"\"\"Plots the correlation\"\"\"\n",
        "  set_plotting_style(fig_width=15)\n",
        "\n",
        "  sns.heatmap(\n",
        "    correlation,\n",
        "    fmt='g',\n",
        "    annot=True,\n",
        "    cmap=COLOR_MAP,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDvGJyeJLZ4R"
      },
      "source": [
        "### Data distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSZ7KQ57R0Fo"
      },
      "source": [
        "It's important to see if the data is balanced or there may be some adjustments to make. We want our model as unbiased as possible with a decent amount of variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqfrnWNSA8f"
      },
      "source": [
        "#### Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sguK8Zz8fqw-"
      },
      "source": [
        "Prints all the given columns as the provided plotting method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNe3DkTOSCJY"
      },
      "outputs": [],
      "source": [
        "def print_cols_as(\n",
        "  df: pd.DataFrame,\n",
        "  method: callable,\n",
        "  cols: Tuple[str] = None,\n",
        "  number_of_cols: int = 4,\n",
        "  style: str = WHITE,\n",
        "  params: dict = {},\n",
        "  fig_width: float = FIGURE_WIDTH,\n",
        "  fig_height: float = FIGURE_HEIGHT,\n",
        "  subplots_adjustment: dict = SUBPLOT_ADJUSTMENT,\n",
        ") -> None:\n",
        "  \"\"\"Prints all the columns as the given method\"\"\"\n",
        "  df = get_df_with_cols( dataframe, cols, only_numeric=True )\n",
        "\n",
        "  # Configure the plotting style\n",
        "  set_plotting_style( style, fig_width, fig_height )\n",
        "\n",
        "  # Configure the subplots\n",
        "  columns = df.columns\n",
        "  n_cols = len(columns)\n",
        "  fig, axes = plt.subplots(int(n_cols / number_of_cols) + 1, number_of_cols, **params)\n",
        "\n",
        "  # set the spacing between subplots\n",
        "  plt.subplots_adjust(**subplots_adjustment)\n",
        "\n",
        "  for index, col in enumerate(columns):\n",
        "    method(ax=axes[int(index / number_of_cols), int(index % number_of_cols)], x=df[col])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Djk36W0fw6-"
      },
      "source": [
        "Prints in one method all the given columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM3yBKwhf38m"
      },
      "outputs": [],
      "source": [
        "def plot_overall(\n",
        "  dataframe: pd.DataFrame,\n",
        "  method: callable,\n",
        "  cols: Tuple[str] = None,\n",
        "  style: str = WHITE,\n",
        "  params: dict = {},\n",
        "  fig_width: float = FIGURE_WIDTH,\n",
        "  fig_height: float = FIGURE_HEIGHT,\n",
        ") -> None:\n",
        "  \"\"\"Plots the dataset\"\"\"\n",
        "  df = get_df_with_cols( dataframe, cols, only_numeric=True )\n",
        "\n",
        "  # Configure the plotting style\n",
        "  set_plotting_style( style, fig_width, fig_height )\n",
        "\n",
        "  # Actually plot\n",
        "  method(data=df, **params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hLmOcMwM9jZ"
      },
      "source": [
        "#### Boxplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EugL7t_dWVv"
      },
      "source": [
        "The total Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Edin1TWSRzOw"
      },
      "outputs": [],
      "source": [
        "def boxplot_distribution(\n",
        "  dataframe: pd.DataFrame,\n",
        "  cols: Tuple[str] = None,\n",
        "  number_of_cols: int = 4,\n",
        ") -> None:\n",
        "  \"\"\"Boxplots the dataset's distribution\"\"\"\n",
        "  print_cols_as(\n",
        "    dataframe=dataframe,\n",
        "    cols=cols,\n",
        "    number_of_cols=number_of_cols,\n",
        "    style=WHITEGRID,\n",
        "    method=sns.boxplot,\n",
        "    params={\n",
        "      'orient':\"h\",\n",
        "      'palette':\"Set2\",\n",
        "    }\n",
        "  )\n",
        "\n",
        "boxplot_distribution( dataframe )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6O3LtwOdY5N"
      },
      "source": [
        "The overall view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiG2VVQ-dbp2"
      },
      "outputs": [],
      "source": [
        "def boxplot_overall(\n",
        "  dataframe: pd.DataFrame,\n",
        "  cols: Tuple[str] = None,\n",
        ") -> None:\n",
        "  \"\"\"Boxplots the dataset\"\"\"\n",
        "  plot_overall(\n",
        "    dataframe=dataframe,\n",
        "    cols=cols,\n",
        "    style=WHITEGRID,\n",
        "    method=sns.boxplot,\n",
        "    params={\n",
        "      'orient':\"v\",\n",
        "      'palette':\"Set2\",\n",
        "    }\n",
        "  )\n",
        "\n",
        "boxplot_overall( dataframe )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1zHGm0oM-9R"
      },
      "source": [
        "#### Histplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebOcJM-Hkuit"
      },
      "source": [
        "The total Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0-d53pBRzox"
      },
      "outputs": [],
      "source": [
        "def histplot_distribution(\n",
        "  dataframe: pd.DataFrame,\n",
        "  cols: Tuple[str] = None,\n",
        "  number_of_cols: int = 4,\n",
        ") -> None:\n",
        "  \"\"\"Histplots the dataset's distribution\"\"\"\n",
        "  print_cols_as(\n",
        "    dataframe=dataframe,\n",
        "    cols=cols,\n",
        "    number_of_cols=number_of_cols,\n",
        "    style=WHITEGRID,\n",
        "    method=sns.histplot,\n",
        "  )\n",
        "\n",
        "boxplot_distribution( dataframe )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S4w5hGNkcSw"
      },
      "source": [
        "The overall view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwNUrCe-kd08"
      },
      "outputs": [],
      "source": [
        "def histplot_overall(\n",
        "  dataframe: pd.DataFrame,\n",
        "  cols: Tuple[str] = None,\n",
        ") -> None:\n",
        "  \"\"\"Histplots the dataset\"\"\"\n",
        "  plot_overall(\n",
        "    dataframe=dataframe,\n",
        "    cols=cols,\n",
        "    style=WHITEGRID,\n",
        "    method=sns.histplot,\n",
        "  )\n",
        "\n",
        "histplot_overall( dataframe )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkheYJU1LziC"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhX_qWmOODPb"
      },
      "source": [
        "### Backup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMzcNeGvOEtB"
      },
      "source": [
        "Create a copy just in case we need to reload the dataframe again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwO8gs7sOHYC"
      },
      "outputs": [],
      "source": [
        "df = dataframe.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOCe1bs3NdWw"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "p-d9C5IENeaj"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDgppxJoL4nZ"
      },
      "source": [
        "### Clean the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N77TYpl3NY0w"
      },
      "source": [
        "Fill, remove, and drop all the columns and values that we may need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAhGP8vrL52B"
      },
      "source": [
        "### Map the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEkkagQ7NNyc"
      },
      "source": [
        "#### Col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDpYewWXNPc5"
      },
      "source": [
        "We need to convert the data from the column \"col\" to \"\" because..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV9SYdBuNNl9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-mFt7S5L0tp"
      },
      "source": [
        "### Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27Jciox1NNMa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jhm2szGL2dA"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPf5xyiNE1R"
      },
      "source": [
        "We apply the MinMax Normalization, because..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oDoOkhjNLcr"
      },
      "outputs": [],
      "source": [
        "def normalize(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Normalizes a DataFrame\"\"\"\n",
        "  df = dataframe.copy()\n",
        "\n",
        "  return df\n",
        "\n",
        "df = normalize(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsasaOB__iUd"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE1z3OD8LyMZ"
      },
      "source": [
        "Now that we have some quality data, it's time to start modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U6V0gnusQjz"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wLmTw2NnsR4r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EO3ORTdsvu7"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YEuWYy5sw1N"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = .15 #@param {'type': 'number'}\n",
        "\n",
        "VALIDATION_SIZE = .4 #@param {'type': 'number'}\n",
        "\n",
        "SEED = 42 #@param {'type': 'integer'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wAd91DgMauB"
      },
      "source": [
        "### Set the seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8ZtJ6FrMcC6"
      },
      "source": [
        "Only for training, evaluation and researching purposes. It should NOT be deployed to production with a fixed seed.\n",
        "\n",
        "It, greatly, helps identify any sort of problem since it should always give the same outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ty2vkfgFMhRB"
      },
      "outputs": [],
      "source": [
        "np.random.seed(SEED) # The answer to all the questions in the universe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMadcR9aLiEx"
      },
      "source": [
        "### Value assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-XWu5M0ME45"
      },
      "source": [
        "It is time to identify the label and separate the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U83z9DVBMGOa"
      },
      "outputs": [],
      "source": [
        "target = 'label'\n",
        "columns = [ col for col in df.columns if col is not target ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r3QlOe0MBTR"
      },
      "source": [
        "And we assign **X** and **y**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6Wz1jUULw_5"
      },
      "outputs": [],
      "source": [
        "X = df[ columns ]\n",
        "y = df[ target ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa_CenOiLj-J"
      },
      "source": [
        "### Validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VcJYylPLwgx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED)\n",
        "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=TEST_SIZE, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQoW7fEzLm0Z"
      },
      "source": [
        "### Model Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ-HpGqPLwSi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukFnzmPzLqkJ"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_QNZitSKMoMo"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  \"\"\"Builds the model\"\"\"\n",
        "  model = None\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9UKnE_WLshA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1qwsFdvMv_3"
      },
      "outputs": [],
      "source": [
        "def train_model(model):\n",
        "  \"\"\"Trains the model\"\"\"\n",
        "  pass\n",
        "\n",
        "# train_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaE2T5BGtWha"
      },
      "source": [
        "### Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90i2kPCttgtK"
      },
      "source": [
        "It is important to have a model ready to use after it's been trained, instead of going through the whole process of cleaning the data, and retraining it each time we may want to use it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "529y-ozXtaKk"
      },
      "source": [
        "#### Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl3-_5aLtsB7"
      },
      "outputs": [],
      "source": [
        "def save_model(model) -> bool:\n",
        "  \"\"\"Saves the model\"\"\"\n",
        "  pass\n",
        "\n",
        "model_was_saved = save_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGGD_z36tcbc"
      },
      "source": [
        "### Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKZPtPmFt3xT"
      },
      "outputs": [],
      "source": [
        "def load_model():\n",
        "  model = None\n",
        "\n",
        "  return model\n",
        "\n",
        "# model = load_model()\n",
        "loaded_model = load_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Fw--5r_joL"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO_L4jadoHI0"
      },
      "source": [
        "### Basic metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm12psTyoIkT"
      },
      "outputs": [],
      "source": [
        "def evalute(model):\n",
        "  \"\"\"Evaluates the model\"\"\"\n",
        "  pass\n",
        "\n",
        "score = evalute(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvZ8eqCVoRMN"
      },
      "source": [
        "### In-detail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR5qXBP0oS5b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAoW7rUYoTIr"
      },
      "source": [
        "### Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UoobaQNuCV6"
      },
      "source": [
        "This is where any necessary comprobation about the results and it's hypothesis will be, after it's already trained and evaluated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhofBKHX_nIM"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "293T4l1AuP7L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bg86l6g_lOT"
      },
      "source": [
        "## Data Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "dPTW7nVA_Ad9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
